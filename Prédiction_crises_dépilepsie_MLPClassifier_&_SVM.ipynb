{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tAeI7SC_aezM"
      },
      "outputs": [],
      "source": [
        "#Importation des Biblio\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions (suppress=True)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import  MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,roc_auc_score,classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CkDPrnGGaezP"
      },
      "outputs": [],
      "source": [
        "#Chargement de base\n",
        "\n",
        "data=pd.read_csv('/content/Base.csv',sep=' ', header=(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "L-vhAF5FaezQ",
        "outputId": "db99997d-e573-4ff3-f5c5-1191b2d651cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   21516.582000  44667.203900  115421.200200  240434.510500  440023.158200  \\\n",
              "0    66341.7319    76972.4981    111452.3341    175722.0050   2.773431e+05   \n",
              "1    22476.6171    32388.9675     60336.8673     97908.6282   1.248140e+05   \n",
              "2     4044.1830     2097.4077      4693.8220     36540.7549   1.336515e+05   \n",
              "3    22604.0750    34253.1060     78658.4935    183111.5509   3.875203e+05   \n",
              "4    21045.2128    37950.6176     89533.9553    169855.6180   2.481682e+05   \n",
              "5     1657.3833       61.7219     14340.6823    104372.0418   3.710113e+05   \n",
              "6     3368.6451     3592.2737     59218.7334    312612.3409   9.319198e+05   \n",
              "7    26833.8860    63134.4729    257819.9441    873399.9962   2.330096e+06   \n",
              "8     9189.2467    66033.7821    266259.5343    714701.2317   1.625082e+06   \n",
              "9    23111.5512    30428.1878     49521.6032     70606.7588   7.760404e+04   \n",
              "\n",
              "   759398.574100  1272766.366300  2064313.195200  3177107.477700  \\\n",
              "0   4.333589e+05    6.952205e+05    1.181772e+06    2.086164e+06   \n",
              "1   1.129392e+05    5.348791e+04    7.307897e+03    1.487606e+05   \n",
              "2   3.289613e+05    6.300081e+05    9.998012e+05    1.355202e+06   \n",
              "3   7.315302e+05    1.233566e+06    1.867248e+06    2.545874e+06   \n",
              "4   2.670043e+05    1.896730e+05    9.726277e+04    2.649468e+05   \n",
              "5   9.368764e+05    1.898126e+06    3.259715e+06    4.889464e+06   \n",
              "6   2.029150e+06    3.588733e+06    5.439074e+06    7.284062e+06   \n",
              "7   5.085033e+06    9.364433e+06    1.482776e+07    2.038705e+07   \n",
              "8   3.330417e+06    6.213302e+06    1.052693e+07    1.615716e+07   \n",
              "9   5.945018e+04    3.440102e+04    7.215444e+04    2.847994e+05   \n",
              "\n",
              "   4545642.108600  ...   91.680700  2531.009100  13725.789700  35564.343200  \\\n",
              "0    3.613615e+06  ...   5973.5464     181.8288     4581.9118    25717.3036   \n",
              "1    7.504049e+05  ...   4740.4096   10316.5948    19566.1880    32205.5605   \n",
              "2    1.589637e+06  ...   1390.8140    1824.2789     1452.2761      586.5759   \n",
              "3    3.127818e+06  ...   6886.5780   12523.7923    19833.9861    28158.4121   \n",
              "4    1.108486e+06  ...    295.1538     455.4406      671.8252      901.9835   \n",
              "5    6.530019e+06  ...      7.4501       8.1534       18.8379       23.6324   \n",
              "6    8.784240e+06  ...     66.8939      29.8034       13.7023       36.1402   \n",
              "7    2.442201e+07  ...   3115.8866    6546.7377    12631.8815    21355.5426   \n",
              "8    2.245975e+07  ...  82495.0322  120375.3306   175730.1143   249633.1153   \n",
              "9    7.690632e+05  ...   7841.7228   13864.8170    23207.4405    36004.1508   \n",
              "\n",
              "   67071.024700  103836.816600  138710.154600  163735.368600  172710.974900  \\\n",
              "0    65286.2862    117270.0184    168814.3120    205029.8222    215274.0359   \n",
              "1    47350.3607     63378.6379     77929.7322     88280.8738     92123.6120   \n",
              "2      100.7999       716.2042      2342.3627      4042.4916      4705.5865   \n",
              "3    36542.7347     43982.7186     49646.1652     52987.3095     53749.9457   \n",
              "4     1098.8371      1251.1999      1384.6284      1517.1457      1620.3564   \n",
              "5       15.3439         5.4855         8.3211        20.9907        27.0657   \n",
              "6       88.0852       147.2398       200.0668       245.2710       278.0043   \n",
              "7    31604.1077     41507.5336     49278.3727     53845.0249     54851.0424   \n",
              "8   338338.7230    432057.7877    515944.5314    573607.8844    592144.5182   \n",
              "9    51314.9966     67077.4106     80569.8699     89211.2209     91338.9393   \n",
              "\n",
              "   0.000000  \n",
              "0       0.0  \n",
              "1       0.0  \n",
              "2       0.0  \n",
              "3       0.0  \n",
              "4       0.0  \n",
              "5       0.0  \n",
              "6       0.0  \n",
              "7       0.0  \n",
              "8       0.0  \n",
              "9       0.0  \n",
              "\n",
              "[10 rows x 322 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50f2d1ad-5c1c-4a56-ab07-bdc5a418e024\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>21516.582000</th>\n",
              "      <th>44667.203900</th>\n",
              "      <th>115421.200200</th>\n",
              "      <th>240434.510500</th>\n",
              "      <th>440023.158200</th>\n",
              "      <th>759398.574100</th>\n",
              "      <th>1272766.366300</th>\n",
              "      <th>2064313.195200</th>\n",
              "      <th>3177107.477700</th>\n",
              "      <th>4545642.108600</th>\n",
              "      <th>...</th>\n",
              "      <th>91.680700</th>\n",
              "      <th>2531.009100</th>\n",
              "      <th>13725.789700</th>\n",
              "      <th>35564.343200</th>\n",
              "      <th>67071.024700</th>\n",
              "      <th>103836.816600</th>\n",
              "      <th>138710.154600</th>\n",
              "      <th>163735.368600</th>\n",
              "      <th>172710.974900</th>\n",
              "      <th>0.000000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66341.7319</td>\n",
              "      <td>76972.4981</td>\n",
              "      <td>111452.3341</td>\n",
              "      <td>175722.0050</td>\n",
              "      <td>2.773431e+05</td>\n",
              "      <td>4.333589e+05</td>\n",
              "      <td>6.952205e+05</td>\n",
              "      <td>1.181772e+06</td>\n",
              "      <td>2.086164e+06</td>\n",
              "      <td>3.613615e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>5973.5464</td>\n",
              "      <td>181.8288</td>\n",
              "      <td>4581.9118</td>\n",
              "      <td>25717.3036</td>\n",
              "      <td>65286.2862</td>\n",
              "      <td>117270.0184</td>\n",
              "      <td>168814.3120</td>\n",
              "      <td>205029.8222</td>\n",
              "      <td>215274.0359</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22476.6171</td>\n",
              "      <td>32388.9675</td>\n",
              "      <td>60336.8673</td>\n",
              "      <td>97908.6282</td>\n",
              "      <td>1.248140e+05</td>\n",
              "      <td>1.129392e+05</td>\n",
              "      <td>5.348791e+04</td>\n",
              "      <td>7.307897e+03</td>\n",
              "      <td>1.487606e+05</td>\n",
              "      <td>7.504049e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>4740.4096</td>\n",
              "      <td>10316.5948</td>\n",
              "      <td>19566.1880</td>\n",
              "      <td>32205.5605</td>\n",
              "      <td>47350.3607</td>\n",
              "      <td>63378.6379</td>\n",
              "      <td>77929.7322</td>\n",
              "      <td>88280.8738</td>\n",
              "      <td>92123.6120</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4044.1830</td>\n",
              "      <td>2097.4077</td>\n",
              "      <td>4693.8220</td>\n",
              "      <td>36540.7549</td>\n",
              "      <td>1.336515e+05</td>\n",
              "      <td>3.289613e+05</td>\n",
              "      <td>6.300081e+05</td>\n",
              "      <td>9.998012e+05</td>\n",
              "      <td>1.355202e+06</td>\n",
              "      <td>1.589637e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>1390.8140</td>\n",
              "      <td>1824.2789</td>\n",
              "      <td>1452.2761</td>\n",
              "      <td>586.5759</td>\n",
              "      <td>100.7999</td>\n",
              "      <td>716.2042</td>\n",
              "      <td>2342.3627</td>\n",
              "      <td>4042.4916</td>\n",
              "      <td>4705.5865</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22604.0750</td>\n",
              "      <td>34253.1060</td>\n",
              "      <td>78658.4935</td>\n",
              "      <td>183111.5509</td>\n",
              "      <td>3.875203e+05</td>\n",
              "      <td>7.315302e+05</td>\n",
              "      <td>1.233566e+06</td>\n",
              "      <td>1.867248e+06</td>\n",
              "      <td>2.545874e+06</td>\n",
              "      <td>3.127818e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>6886.5780</td>\n",
              "      <td>12523.7923</td>\n",
              "      <td>19833.9861</td>\n",
              "      <td>28158.4121</td>\n",
              "      <td>36542.7347</td>\n",
              "      <td>43982.7186</td>\n",
              "      <td>49646.1652</td>\n",
              "      <td>52987.3095</td>\n",
              "      <td>53749.9457</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21045.2128</td>\n",
              "      <td>37950.6176</td>\n",
              "      <td>89533.9553</td>\n",
              "      <td>169855.6180</td>\n",
              "      <td>2.481682e+05</td>\n",
              "      <td>2.670043e+05</td>\n",
              "      <td>1.896730e+05</td>\n",
              "      <td>9.726277e+04</td>\n",
              "      <td>2.649468e+05</td>\n",
              "      <td>1.108486e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>295.1538</td>\n",
              "      <td>455.4406</td>\n",
              "      <td>671.8252</td>\n",
              "      <td>901.9835</td>\n",
              "      <td>1098.8371</td>\n",
              "      <td>1251.1999</td>\n",
              "      <td>1384.6284</td>\n",
              "      <td>1517.1457</td>\n",
              "      <td>1620.3564</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1657.3833</td>\n",
              "      <td>61.7219</td>\n",
              "      <td>14340.6823</td>\n",
              "      <td>104372.0418</td>\n",
              "      <td>3.710113e+05</td>\n",
              "      <td>9.368764e+05</td>\n",
              "      <td>1.898126e+06</td>\n",
              "      <td>3.259715e+06</td>\n",
              "      <td>4.889464e+06</td>\n",
              "      <td>6.530019e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>7.4501</td>\n",
              "      <td>8.1534</td>\n",
              "      <td>18.8379</td>\n",
              "      <td>23.6324</td>\n",
              "      <td>15.3439</td>\n",
              "      <td>5.4855</td>\n",
              "      <td>8.3211</td>\n",
              "      <td>20.9907</td>\n",
              "      <td>27.0657</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3368.6451</td>\n",
              "      <td>3592.2737</td>\n",
              "      <td>59218.7334</td>\n",
              "      <td>312612.3409</td>\n",
              "      <td>9.319198e+05</td>\n",
              "      <td>2.029150e+06</td>\n",
              "      <td>3.588733e+06</td>\n",
              "      <td>5.439074e+06</td>\n",
              "      <td>7.284062e+06</td>\n",
              "      <td>8.784240e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>66.8939</td>\n",
              "      <td>29.8034</td>\n",
              "      <td>13.7023</td>\n",
              "      <td>36.1402</td>\n",
              "      <td>88.0852</td>\n",
              "      <td>147.2398</td>\n",
              "      <td>200.0668</td>\n",
              "      <td>245.2710</td>\n",
              "      <td>278.0043</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>26833.8860</td>\n",
              "      <td>63134.4729</td>\n",
              "      <td>257819.9441</td>\n",
              "      <td>873399.9962</td>\n",
              "      <td>2.330096e+06</td>\n",
              "      <td>5.085033e+06</td>\n",
              "      <td>9.364433e+06</td>\n",
              "      <td>1.482776e+07</td>\n",
              "      <td>2.038705e+07</td>\n",
              "      <td>2.442201e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>3115.8866</td>\n",
              "      <td>6546.7377</td>\n",
              "      <td>12631.8815</td>\n",
              "      <td>21355.5426</td>\n",
              "      <td>31604.1077</td>\n",
              "      <td>41507.5336</td>\n",
              "      <td>49278.3727</td>\n",
              "      <td>53845.0249</td>\n",
              "      <td>54851.0424</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9189.2467</td>\n",
              "      <td>66033.7821</td>\n",
              "      <td>266259.5343</td>\n",
              "      <td>714701.2317</td>\n",
              "      <td>1.625082e+06</td>\n",
              "      <td>3.330417e+06</td>\n",
              "      <td>6.213302e+06</td>\n",
              "      <td>1.052693e+07</td>\n",
              "      <td>1.615716e+07</td>\n",
              "      <td>2.245975e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>82495.0322</td>\n",
              "      <td>120375.3306</td>\n",
              "      <td>175730.1143</td>\n",
              "      <td>249633.1153</td>\n",
              "      <td>338338.7230</td>\n",
              "      <td>432057.7877</td>\n",
              "      <td>515944.5314</td>\n",
              "      <td>573607.8844</td>\n",
              "      <td>592144.5182</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23111.5512</td>\n",
              "      <td>30428.1878</td>\n",
              "      <td>49521.6032</td>\n",
              "      <td>70606.7588</td>\n",
              "      <td>7.760404e+04</td>\n",
              "      <td>5.945018e+04</td>\n",
              "      <td>3.440102e+04</td>\n",
              "      <td>7.215444e+04</td>\n",
              "      <td>2.847994e+05</td>\n",
              "      <td>7.690632e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>7841.7228</td>\n",
              "      <td>13864.8170</td>\n",
              "      <td>23207.4405</td>\n",
              "      <td>36004.1508</td>\n",
              "      <td>51314.9966</td>\n",
              "      <td>67077.4106</td>\n",
              "      <td>80569.8699</td>\n",
              "      <td>89211.2209</td>\n",
              "      <td>91338.9393</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 322 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50f2d1ad-5c1c-4a56-ab07-bdc5a418e024')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50f2d1ad-5c1c-4a56-ab07-bdc5a418e024 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50f2d1ad-5c1c-4a56-ab07-bdc5a418e024');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Afficher les 10 1ères lignes\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVZhtbZoaezS",
        "outputId": "5814ea66-7c10-449b-b93d-f83c73f74f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3598 entries, 0 to 3597\n",
            "Columns: 322 entries, 21516.582000 to 0.000000\n",
            "dtypes: float64(322)\n",
            "memory usage: 8.8 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# infromation of the data\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tdcUl8_aezS",
        "outputId": "5014d097-da02-4519-f01e-09b87151b39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Dataset: (3598, 322)\n",
            "Number of rows: 3598\n",
            "Number of columns :  322\n"
          ]
        }
      ],
      "source": [
        "print('Shape of Dataset:',data.shape)\n",
        "print('Number of rows:',data.shape[0])\n",
        "print('Number of columns : ',data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TzBESM9aezT",
        "outputId": "0d341702-bd57-4713-9ea2-9a98bfb4f7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is there any null value : False\n"
          ]
        }
      ],
      "source": [
        "# checking for null value \n",
        "print(\"is there any null value :\",data.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "eK5206IOaezT",
        "outputId": "c86d44fa-447a-43ea-9006-3afaa15e65be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       21516.582000  44667.203900  115421.200200  240434.510500  \\\n",
              "count  3.598000e+03  3.598000e+03   3.598000e+03   3.598000e+03   \n",
              "mean   1.171894e+06  1.273386e+06   1.574855e+06   2.070603e+06   \n",
              "std    7.556232e+06  7.583755e+06   7.840813e+06   8.578006e+06   \n",
              "min    1.480000e-02  5.872900e+00   1.006027e+02   4.568820e+01   \n",
              "25%    1.004928e+04  3.166373e+04   7.902050e+04   1.680742e+05   \n",
              "50%    6.792311e+04  1.272266e+05   2.673497e+05   5.192075e+05   \n",
              "75%    6.026420e+05  7.306395e+05   1.058165e+06   1.546058e+06   \n",
              "max    3.215172e+08  3.112352e+08   2.819806e+08   2.382507e+08   \n",
              "\n",
              "       440023.158200  759398.574100  1272766.366300  2064313.195200  \\\n",
              "count   3.598000e+03   3.598000e+03    3.598000e+03    3.598000e+03   \n",
              "mean    2.759920e+06   3.653075e+06    4.768597e+06    6.118193e+06   \n",
              "std     9.810898e+06   1.144968e+07    1.345362e+07    1.583210e+07   \n",
              "min     1.539346e+02   1.135527e+02    1.500209e+02    3.631578e+02   \n",
              "25%     2.807818e+05   4.079328e+05    5.319674e+05    6.974253e+05   \n",
              "50%     8.451065e+05   1.228786e+06    1.671133e+06    2.183593e+06   \n",
              "75%     2.235219e+06   3.141571e+06    4.389168e+06    6.024560e+06   \n",
              "max     2.341321e+08   2.651344e+08    2.942489e+08    3.564233e+08   \n",
              "\n",
              "       3177107.477700  4545642.108600  ...     91.680700   2531.009100  \\\n",
              "count    3.598000e+03    3.598000e+03  ...  3.598000e+03  3.598000e+03   \n",
              "mean     7.683038e+06    9.392830e+06  ...  8.902626e+03  1.127873e+04   \n",
              "std      1.860261e+07    2.167203e+07  ...  6.193012e+04  7.654518e+04   \n",
              "min      3.123163e+02    3.224819e+02  ...  3.920000e-02  1.550000e-02   \n",
              "25%      9.359549e+05    1.256345e+06  ...  2.072134e+02  2.018498e+02   \n",
              "50%      2.732234e+06    3.480060e+06  ...  8.885280e+02  9.789750e+02   \n",
              "75%      7.477858e+06    9.296114e+06  ...  4.220525e+03  5.359304e+03   \n",
              "max      4.810619e+08    6.235253e+08  ...  1.752914e+06  2.807571e+06   \n",
              "\n",
              "       13725.789700  35564.343200  67071.024700  103836.816600  138710.154600  \\\n",
              "count  3.598000e+03  3.598000e+03  3.598000e+03   3.598000e+03   3.598000e+03   \n",
              "mean   1.533843e+04  2.162066e+04  3.017366e+04   4.014481e+04   4.971930e+04   \n",
              "std    1.017956e+05  1.373418e+05  1.831454e+05   2.375467e+05   2.928591e+05   \n",
              "min    1.561000e-01  6.586000e-01  2.740000e-02   1.481000e-01   2.230000e-01   \n",
              "25%    2.119770e+02  2.541155e+02  4.017436e+02   6.385327e+02   8.934555e+02   \n",
              "50%    1.211308e+03  1.560921e+03  2.324349e+03   3.343360e+03   4.414033e+03   \n",
              "75%    6.969233e+03  1.003482e+04  1.391438e+04   1.903103e+04   2.363860e+04   \n",
              "max    4.145090e+06  5.595592e+06  6.873093e+06   7.652316e+06   7.988904e+06   \n",
              "\n",
              "       163735.368600  172710.974900     0.000000  \n",
              "count   3.598000e+03   3.598000e+03  3598.000000  \n",
              "mean    5.660340e+04   5.890739e+04     0.272929  \n",
              "std     3.354488e+05   3.521522e+05     0.470416  \n",
              "min     3.718300e+00   9.917000e-01     0.000000  \n",
              "25%     1.106013e+03   1.147857e+03     0.000000  \n",
              "50%     5.050194e+03   5.301405e+03     0.000000  \n",
              "75%     2.725609e+04   2.839647e+04     1.000000  \n",
              "max     9.992543e+06   1.127103e+07     2.000000  \n",
              "\n",
              "[8 rows x 322 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5f7414d-4693-4eda-b911-d760ff37a6f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>21516.582000</th>\n",
              "      <th>44667.203900</th>\n",
              "      <th>115421.200200</th>\n",
              "      <th>240434.510500</th>\n",
              "      <th>440023.158200</th>\n",
              "      <th>759398.574100</th>\n",
              "      <th>1272766.366300</th>\n",
              "      <th>2064313.195200</th>\n",
              "      <th>3177107.477700</th>\n",
              "      <th>4545642.108600</th>\n",
              "      <th>...</th>\n",
              "      <th>91.680700</th>\n",
              "      <th>2531.009100</th>\n",
              "      <th>13725.789700</th>\n",
              "      <th>35564.343200</th>\n",
              "      <th>67071.024700</th>\n",
              "      <th>103836.816600</th>\n",
              "      <th>138710.154600</th>\n",
              "      <th>163735.368600</th>\n",
              "      <th>172710.974900</th>\n",
              "      <th>0.000000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>3598.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.171894e+06</td>\n",
              "      <td>1.273386e+06</td>\n",
              "      <td>1.574855e+06</td>\n",
              "      <td>2.070603e+06</td>\n",
              "      <td>2.759920e+06</td>\n",
              "      <td>3.653075e+06</td>\n",
              "      <td>4.768597e+06</td>\n",
              "      <td>6.118193e+06</td>\n",
              "      <td>7.683038e+06</td>\n",
              "      <td>9.392830e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>8.902626e+03</td>\n",
              "      <td>1.127873e+04</td>\n",
              "      <td>1.533843e+04</td>\n",
              "      <td>2.162066e+04</td>\n",
              "      <td>3.017366e+04</td>\n",
              "      <td>4.014481e+04</td>\n",
              "      <td>4.971930e+04</td>\n",
              "      <td>5.660340e+04</td>\n",
              "      <td>5.890739e+04</td>\n",
              "      <td>0.272929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.556232e+06</td>\n",
              "      <td>7.583755e+06</td>\n",
              "      <td>7.840813e+06</td>\n",
              "      <td>8.578006e+06</td>\n",
              "      <td>9.810898e+06</td>\n",
              "      <td>1.144968e+07</td>\n",
              "      <td>1.345362e+07</td>\n",
              "      <td>1.583210e+07</td>\n",
              "      <td>1.860261e+07</td>\n",
              "      <td>2.167203e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>6.193012e+04</td>\n",
              "      <td>7.654518e+04</td>\n",
              "      <td>1.017956e+05</td>\n",
              "      <td>1.373418e+05</td>\n",
              "      <td>1.831454e+05</td>\n",
              "      <td>2.375467e+05</td>\n",
              "      <td>2.928591e+05</td>\n",
              "      <td>3.354488e+05</td>\n",
              "      <td>3.521522e+05</td>\n",
              "      <td>0.470416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.480000e-02</td>\n",
              "      <td>5.872900e+00</td>\n",
              "      <td>1.006027e+02</td>\n",
              "      <td>4.568820e+01</td>\n",
              "      <td>1.539346e+02</td>\n",
              "      <td>1.135527e+02</td>\n",
              "      <td>1.500209e+02</td>\n",
              "      <td>3.631578e+02</td>\n",
              "      <td>3.123163e+02</td>\n",
              "      <td>3.224819e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>3.920000e-02</td>\n",
              "      <td>1.550000e-02</td>\n",
              "      <td>1.561000e-01</td>\n",
              "      <td>6.586000e-01</td>\n",
              "      <td>2.740000e-02</td>\n",
              "      <td>1.481000e-01</td>\n",
              "      <td>2.230000e-01</td>\n",
              "      <td>3.718300e+00</td>\n",
              "      <td>9.917000e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.004928e+04</td>\n",
              "      <td>3.166373e+04</td>\n",
              "      <td>7.902050e+04</td>\n",
              "      <td>1.680742e+05</td>\n",
              "      <td>2.807818e+05</td>\n",
              "      <td>4.079328e+05</td>\n",
              "      <td>5.319674e+05</td>\n",
              "      <td>6.974253e+05</td>\n",
              "      <td>9.359549e+05</td>\n",
              "      <td>1.256345e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>2.072134e+02</td>\n",
              "      <td>2.018498e+02</td>\n",
              "      <td>2.119770e+02</td>\n",
              "      <td>2.541155e+02</td>\n",
              "      <td>4.017436e+02</td>\n",
              "      <td>6.385327e+02</td>\n",
              "      <td>8.934555e+02</td>\n",
              "      <td>1.106013e+03</td>\n",
              "      <td>1.147857e+03</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.792311e+04</td>\n",
              "      <td>1.272266e+05</td>\n",
              "      <td>2.673497e+05</td>\n",
              "      <td>5.192075e+05</td>\n",
              "      <td>8.451065e+05</td>\n",
              "      <td>1.228786e+06</td>\n",
              "      <td>1.671133e+06</td>\n",
              "      <td>2.183593e+06</td>\n",
              "      <td>2.732234e+06</td>\n",
              "      <td>3.480060e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>8.885280e+02</td>\n",
              "      <td>9.789750e+02</td>\n",
              "      <td>1.211308e+03</td>\n",
              "      <td>1.560921e+03</td>\n",
              "      <td>2.324349e+03</td>\n",
              "      <td>3.343360e+03</td>\n",
              "      <td>4.414033e+03</td>\n",
              "      <td>5.050194e+03</td>\n",
              "      <td>5.301405e+03</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.026420e+05</td>\n",
              "      <td>7.306395e+05</td>\n",
              "      <td>1.058165e+06</td>\n",
              "      <td>1.546058e+06</td>\n",
              "      <td>2.235219e+06</td>\n",
              "      <td>3.141571e+06</td>\n",
              "      <td>4.389168e+06</td>\n",
              "      <td>6.024560e+06</td>\n",
              "      <td>7.477858e+06</td>\n",
              "      <td>9.296114e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>4.220525e+03</td>\n",
              "      <td>5.359304e+03</td>\n",
              "      <td>6.969233e+03</td>\n",
              "      <td>1.003482e+04</td>\n",
              "      <td>1.391438e+04</td>\n",
              "      <td>1.903103e+04</td>\n",
              "      <td>2.363860e+04</td>\n",
              "      <td>2.725609e+04</td>\n",
              "      <td>2.839647e+04</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.215172e+08</td>\n",
              "      <td>3.112352e+08</td>\n",
              "      <td>2.819806e+08</td>\n",
              "      <td>2.382507e+08</td>\n",
              "      <td>2.341321e+08</td>\n",
              "      <td>2.651344e+08</td>\n",
              "      <td>2.942489e+08</td>\n",
              "      <td>3.564233e+08</td>\n",
              "      <td>4.810619e+08</td>\n",
              "      <td>6.235253e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>1.752914e+06</td>\n",
              "      <td>2.807571e+06</td>\n",
              "      <td>4.145090e+06</td>\n",
              "      <td>5.595592e+06</td>\n",
              "      <td>6.873093e+06</td>\n",
              "      <td>7.652316e+06</td>\n",
              "      <td>7.988904e+06</td>\n",
              "      <td>9.992543e+06</td>\n",
              "      <td>1.127103e+07</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 322 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5f7414d-4693-4eda-b911-d760ff37a6f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5f7414d-4693-4eda-b911-d760ff37a6f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5f7414d-4693-4eda-b911-d760ff37a6f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4-qTw0maezU",
        "outputId": "4ef94839-aff8-48c2-f0e6-042e510e448b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21516.582000     0\n",
              "44667.203900     0\n",
              "115421.200200    0\n",
              "240434.510500    0\n",
              "440023.158200    0\n",
              "                ..\n",
              "103836.816600    0\n",
              "138710.154600    0\n",
              "163735.368600    0\n",
              "172710.974900    0\n",
              "0.000000         0\n",
              "Length: 322, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Missing values (éviter les NaN)\n",
        "data.isnull().sum()\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84l0t9I_aezY",
        "outputId": "31a39952-fec5-4111-ed9c-956cc73503d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 66341.7319,  76972.4981, 111452.3341, ..., 205029.8222,\n",
              "        215274.0359,      0.    ],\n",
              "       [ 22476.6171,  32388.9675,  60336.8673, ...,  88280.8738,\n",
              "         92123.612 ,      0.    ],\n",
              "       [  4044.183 ,   2097.4077,   4693.822 , ...,   4042.4916,\n",
              "          4705.5865,      0.    ],\n",
              "       ...,\n",
              "       [258256.6851, 236853.4525, 205626.2906, ...,    363.2694,\n",
              "           376.4815,      0.    ],\n",
              "       [115193.7837, 173024.6757, 379576.133 , ...,    337.7571,\n",
              "           299.85  ,      0.    ],\n",
              "       [405489.1584, 422709.9614, 495790.9409, ...,    301.076 ,\n",
              "           381.2578,      0.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Convert the data into an array\n",
        "dataset = data.values\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lW30yw2KaezZ"
      },
      "outputs": [],
      "source": [
        "#Split the dataset into independent and dependent datasets\n",
        "\n",
        "X = dataset[:, 0:321] #Get all the rows from columns [1,321] (Features)\n",
        "Y = dataset[:,321] #Get all the rows from last column (Target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMCihXbXaezZ",
        "outputId": "8864396c-1486-416e-ce3e-9c40af97e9f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00020634, 0.00024729, 0.00039489, ..., 0.02113107, 0.02051792,\n",
              "        0.01909968],\n",
              "       [0.00006991, 0.00010405, 0.00021362, ..., 0.00975472, 0.00883431,\n",
              "        0.0081734 ],\n",
              "       [0.00001258, 0.00000672, 0.00001629, ..., 0.00029317, 0.00040418,\n",
              "        0.00041741],\n",
              "       ...,\n",
              "       [0.00080324, 0.00076099, 0.00072886, ..., 0.00003461, 0.00003598,\n",
              "        0.00003331],\n",
              "       [0.00035828, 0.00055591, 0.00134575, ..., 0.00003997, 0.00003343,\n",
              "        0.00002652],\n",
              "       [0.00126117, 0.00135815, 0.00175789, ..., 0.0000267 , 0.00002976,\n",
              "        0.00003374]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Normalization\n",
        "#Use the min-maxScaler method from preprocessing which scales the dataset so that all\n",
        "#the features lie between 0 and 1 inclusive\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f1raOj1qaeza"
      },
      "outputs": [],
      "source": [
        "#split the data into 80% training and 20% (testing (10%) and validating (10%))\n",
        "\n",
        "X_train, X_val_test, Y_train, Y_val_test = train_test_split(X_scale, Y, test_size=0.2)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, test_size=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxHJnb-Aaezb",
        "outputId": "e122e70b-3966-46fa-8496-68e66bccf8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2878, 321) (360, 321) (360, 321) (2878,) (360,) (360,)\n"
          ]
        }
      ],
      "source": [
        "#Vérifier le chargement des données\n",
        "\n",
        "#The training set has 2878 data points while the validation and test set have 360 data points each.\n",
        "#The X variables have 321 input features\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Le50XHaezb",
        "outputId": "6b48fbc4-84e8-4090-9986-4596e6bee968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0.0: 2657, 1.0: 900, 2.0: 41})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "histogram=Counter(Y)\n",
        "print(histogram) #donne un dict contennant le nbre d occurences de 0 et 1 cle et\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ENpKD5ALaezc",
        "outputId": "20535c2e-fcca-48ec-c745-8d3cbb0dd9d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.bar(histogram.keys(),histogram.values(), 0.2)\n",
        "plt.show()\n",
        "#afficer le nbre d instance de la colonne Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mXXyF2haezc",
        "outputId": "2dc6aed1-f3c5-4950-9bf7-703eb47b2c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "interictal : 0.738 et preictal : 0.250 et ictal : 0.011\n"
          ]
        }
      ],
      "source": [
        "inter=np.sum(Y==0)/len(Y) #len: total\n",
        "pre=np.sum(Y==1)/len(Y)\n",
        "ictal=np.sum(Y==2)/len(Y)\n",
        "#moyenne de nbr des y\n",
        "print('interictal : {0:.3f} et preictal : {1:.3f} et ictal : {2:.3f}'.format(inter,pre,ictal))\n",
        "#0: la premiere variable et 1 la deuxieme variable 3f: :3chiffres apres la virgule"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP classsifier**"
      ],
      "metadata": {
        "id": "q4So28RbhmUi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I5a2HmcVaezd"
      },
      "outputs": [],
      "source": [
        "#Utiliser l'algorithme de RESEAUX DE NEURONES MULTICOUCHES pour faire notre ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tyFzlzHsaeze"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "model =MLPClassifier(hidden_layer_sizes=(20,10),alpha=0.001, max_iter=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22ZFy_taeze",
        "outputId": "df022a33-5bc1-4033-fd41-f9236c45975d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.001, hidden_layer_sizes=(20, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Train model\n",
        "model.fit(X_train, Y_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Yk4_p4aezf",
        "outputId": "18add09c-588a-4f3a-bedc-1b0ed56d9518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 2. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "#test model\n",
        "prediction = model.predict(X_test)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZBwrPoVaezf",
        "outputId": "9e4688c8-a7e0-4ded-c9d0-4d3659671377"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.93698755, 0.06158253, 0.00142992],\n",
              "       [0.99997728, 0.00001947, 0.00000325],\n",
              "       [0.99905972, 0.00035966, 0.00058061],\n",
              "       ...,\n",
              "       [0.99942213, 0.00038771, 0.00019016],\n",
              "       [0.99063831, 0.0077953 , 0.0015664 ],\n",
              "       [0.90165701, 0.00867531, 0.08966767]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#Predict probabilities\n",
        "proba = model.predict_proba(X_test)\n",
        "proba = np.asarray(proba)\n",
        "proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sELKmlPaezg",
        "outputId": "d10c5476-f962-46a9-9e15-4e0dfa81a5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracty of MLPClassifier Model :  0.8361111111111111\n"
          ]
        }
      ],
      "source": [
        "accuracies =  {} \n",
        "model_accuracy = model.score(X_test,Y_test)\n",
        "accuracies['MLPClassifier'] = model_accuracy\n",
        "print(\"Testing Accuracty of MLPClassifier Model : \",model_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmCMtv4daezg",
        "outputId": "0d1c188f-c1f0-4244-c1d6-05d1818d607c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[251,  26,   1],\n",
              "       [ 32,  48,   0],\n",
              "       [  0,   0,   2]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, prediction)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dEdvhVCMaezh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**"
      ],
      "metadata": {
        "id": "Z3DRwsUVhyiK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfVQn67Gaezh",
        "outputId": "5cd91369-a586-462f-fb10-c8a0ae6da9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 2s 3ms/step - loss: 2.3834 - accuracy: 0.2484\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 2.4779 - accuracy: 0.2484\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 2.4651 - accuracy: 0.2484\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 2.5378 - accuracy: 0.2484\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 2.4113 - accuracy: 0.2484\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 2.4110 - accuracy: 0.2484\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 2.4992 - accuracy: 0.2484\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 2.3936 - accuracy: 0.2484\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2.3754 - accuracy: 0.2484\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 2.4720 - accuracy: 0.2484\n",
            "12/12 - 0s - loss: 2.8702 - accuracy: 0.2222 - 154ms/epoch - 13ms/step\n",
            "\n",
            "Test accuracy: 0.2222222238779068\n"
          ]
        }
      ],
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1,kernel_regularizer=l2(0.1)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='squared_hinge',\n",
        "              optimizer='adadelta',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculer les valeurs loss et précision pour la base de test\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=1, batch_size=32)\n",
        "\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYjfHa5XiHld",
        "outputId": "e77f1609-df5d-4e0b-8b43-8be3c89b7909"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step - loss: 2.8702 - accuracy: 0.2222\n",
            "Test loss:  2.8701822757720947\n",
            "Test accuracy:  0.2222222238779068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a prediction\n",
        "#La génération de prédictions sur de nouvelles données est toute aussi simple :\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "print(prediction)\n",
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9yYhOauiMMQ",
        "outputId": "56f232fa-dfa1-4f13-e566-a0aea0078107"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "[0. 0. 0. 0. 1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_train[1:2], batch_size=None, verbose=0, steps=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bqyFGOUiZfK",
        "outputId": "dc875002-e5dc-491f-d419-2db82a27ee78"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[1:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcTC4_2Fie4Z",
        "outputId": "61ef59ea-7308-4414-cd53-0ce507d6b26a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "# Create the tflite model file\n",
        "tflite_model_name = \"mymodelSVM.tflite\"\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)\n",
        "# Set quantize to true \n",
        "converter.post_training_quantize=True"
      ],
      "metadata": {
        "id": "Kgc9fpLuihhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMMyiT_2ipbD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Prédiction_crises_dépilepsie-MLPClassifier_&_SVM.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}